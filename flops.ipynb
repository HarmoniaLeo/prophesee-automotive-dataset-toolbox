{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, bias=False, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes, kernel_size=3, bias=False, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # SE\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_down = nn.Conv2d(\n",
    "            planes, planes // 4, kernel_size=1, bias=False)\n",
    "        self.conv_up = nn.Conv2d(\n",
    "            planes // 4, planes, kernel_size=1, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        # Downsample\n",
    "        self.downsample = nn.Conv2d(inplanes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "        self.bn4 = nn.BatchNorm2d(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out1 = self.global_pool(out)\n",
    "        out1 = self.conv_down(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.conv_up(out1)\n",
    "        out1 = self.sig(out1)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.bn4(residual)\n",
    "\n",
    "        res = out1 * out + residual\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNet(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SEResNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Sigmoid'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 1.43986304G\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "dummy_images = torch.rand(1, 32, 320, 80)\n",
    "flops, params = profile(Bottleneck(64, 128, 2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.SEResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.6045696G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 10, 240, 320)\n",
    "flops, params = profile(SEResNet(10), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, stride):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel for both cnn and rnn.\n",
    "        cnn_dropout, rnn_dropout: float\n",
    "            cnn_dropout: dropout rate for convolutional input.\n",
    "            rnn_dropout: dropout rate for convolutional state.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        peephole: bool\n",
    "            add connection between cell state to gates\n",
    "        layer_norm: bool\n",
    "            layer normalization \n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = int(self.kernel_size/2)\n",
    "        self.stride = stride\n",
    "        self.bias = True\n",
    "        \n",
    "        self.input_conv = nn.Conv2d(in_channels=self.input_dim, out_channels=4*self.hidden_dim,\n",
    "                                  kernel_size=self.kernel_size,\n",
    "                                  stride = self.stride,\n",
    "                                  padding=self.padding,\n",
    "                                  bias=self.bias)\n",
    "        self.rnn_conv = nn.Conv2d(self.hidden_dim, out_channels=4*self.hidden_dim, \n",
    "                                  kernel_size = self.kernel_size,\n",
    "                                  padding=math.floor(self.kernel_size/2),\n",
    "                                  bias=self.bias)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x_conv = self.input_conv(x)\n",
    "\n",
    "        self.h = Variable(torch.zeros((x_conv.shape[0], self.hidden_dim, x_conv.shape[2], x_conv.shape[3])).to(x.device))\n",
    "        self.c = Variable(torch.zeros((x_conv.shape[0], self.hidden_dim, x_conv.shape[2], x_conv.shape[3])).to(x.device))\n",
    "        \n",
    "        h_cur, c_cur = self.h, self.c\n",
    "\n",
    "        # separate i, f, c o\n",
    "        x_i, x_f, x_c, x_o = torch.split(x_conv, self.hidden_dim, dim=1)\n",
    "        \n",
    "        h_conv = self.rnn_conv(h_cur)\n",
    "        # separate i, f, c o\n",
    "        h_i, h_f, h_c, h_o = torch.split(h_conv, self.hidden_dim, dim=1)\n",
    "        \n",
    "        f = torch.sigmoid((x_f + h_f))  #H/2 * W/2 * 256\n",
    "        i = torch.sigmoid((x_i + h_i))  #H/2 * W/2 * 256\n",
    "        \n",
    "        g = torch.tanh((x_c + h_c))  #H/2 * W/2 * 256\n",
    "        c_next = f * c_cur + i * g  #3 * H/2 * W/2 * 256\n",
    "\n",
    "        o = torch.sigmoid((x_o + h_o))  #H/2 * W/2 * 256\n",
    "\n",
    "        h_next = o * torch.tanh(c_next)  #H/2 * W/2 * 256\n",
    "\n",
    "        self.h = h_next\n",
    "        self.c = c_next\n",
    "        self.has_memory = True\n",
    "\n",
    "        return h_next   #H/2 * W/2 * 256 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.ConvLSTMCell'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.01888256G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 2, 3)\n",
    "flops, params = profile(ConvLSTMCell(256,256,3,2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cls_header = nn.Conv2d(256, 6 * 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.reg_header = nn.Conv2d(256, 6 * 4, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = self.cls_header(x)\n",
    "        x2 = self.reg_header(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.BoxPredictor'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.00019362G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 1, 1)\n",
    "flops, params = profile(BoxPredictor(), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Focus(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, ksize=1, stride=1, act=\"gelu\"):\n",
    "        super().__init__()\n",
    "        pad = (ksize - 1) // 2\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels * 4,\n",
    "            out_channels,\n",
    "            kernel_size=ksize,\n",
    "            stride=stride,\n",
    "            padding=pad,\n",
    "            groups=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def patch_and_conv(self, x, conv):\n",
    "        # shape of x (b,c,w,h) -> y(b,4c,w/2,h/2)\n",
    "        patch_top_left = x[..., ::2, ::2]\n",
    "        patch_top_right = x[..., ::2, 1::2]\n",
    "        patch_bot_left = x[..., 1::2, ::2]\n",
    "        patch_bot_right = x[..., 1::2, 1::2]\n",
    "        x = torch.cat(\n",
    "            (\n",
    "                patch_top_left,\n",
    "                patch_bot_left,\n",
    "                patch_top_right,\n",
    "                patch_bot_right,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "        return self.bn(conv(x))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.patch_and_conv(x, self.conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Focus'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 3.79584512G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 10, 512, 640)\n",
    "flops, params = profile(Focus(10, 64, 3), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dark1(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        pad = (3 - 1) // 2\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=pad,\n",
    "            groups=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels//2,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//2)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels//2,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.bn3(self.conv3(self.bn2(self.conv2(self.bn(self.conv(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.dark1'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.128098304G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 16, 20)\n",
    "flops, params = profile(dark1(256,256,2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dark2(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        pad = (3 - 1) // 2\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=pad,\n",
    "            groups=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels//2,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//2)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels//2,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels//2,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels//2)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            out_channels//2,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn5 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.bn5(self.conv5(self.bn4(self.conv4(self.bn3(self.conv3(self.bn2(self.conv2(self.bn(self.conv(x))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.dark2'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.677931008G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 32, 40)\n",
    "flops, params = profile(dark2(256,256,2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spp_block(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        hidden_channels = out_channels // 2\n",
    "        self.bconv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bbn1 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "        self.p1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=5 // 2)\n",
    "        self.p2 = nn.MaxPool2d(kernel_size=9, stride=1, padding=9 // 2)\n",
    "        self.p3 = nn.MaxPool2d(kernel_size=13, stride=1, padding=13 // 2)\n",
    "\n",
    "        conv2_channels = hidden_channels * 4\n",
    "\n",
    "        self.bconv2 = nn.Conv2d(\n",
    "            conv2_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bbn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn5 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.conv(x))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.bbn1(self.bconv1(x))\n",
    "        x1 = self.p1(x)\n",
    "        x2 = self.p2(x)\n",
    "        x3 = self.p3(x)\n",
    "        x = self.bbn2(self.bconv2(torch.cat([x, x1, x2, x3], dim=1)))\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.spp_block'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.111353856G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 8, 10)\n",
    "flops, params = profile(spp_block(256,256), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fpn(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lc0 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.lc0bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        self.c3p4c1 = nn.Conv2d(\n",
    "            512,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.c3p4c1bn = nn.BatchNorm2d(256)\n",
    "        self.c3p4c2 = nn.Conv2d(\n",
    "            512,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.c3p4c2bn = nn.BatchNorm2d(256)\n",
    "        self.c3p4bc1 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.c3p4bc1bn = nn.BatchNorm2d(256)\n",
    "        self.c3p4bc2 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.c3p4bc2bn = nn.BatchNorm2d(256)\n",
    "        self.c3p4c3 = nn.Conv2d(\n",
    "            512,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.c3p4c3bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.rc1 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.rc1bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.buc2 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=2,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.buc2bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.buc1 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=2,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.buc1bn = nn.BatchNorm2d(256)\n",
    "\n",
    "    \n",
    "    def forward(self, features):\n",
    "        [x2, x1, x0] = features\n",
    "\n",
    "        fpn_out0 = self.lc0bn(self.lc0(x0))  # \n",
    "        f_out0 = self.upsample(fpn_out0)  # \n",
    "        f_out0 = torch.cat([f_out0, x1], 1)  # \n",
    "        x_1 = self.c3p4c1bn(self.c3p4c1(f_out0))\n",
    "        x_2 = self.c3p4c2bn(self.c3p4c2(f_out0))\n",
    "        x_1 = self.c3p4bc1bn(self.c3p4bc1(x_1))\n",
    "        x_1 = self.c3p4bc2bn(self.c3p4bc2(x_1))\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        f_out0 = self.c3p4c3bn(self.c3p4c3(x))\n",
    "\n",
    "        fpn_out1 = self.rc1bn(self.rc1(f_out0))  # \n",
    "        f_out1 = self.upsample(fpn_out1)  # \n",
    "        f_out1 = torch.cat([f_out1, x2], 1)  # \n",
    "        x_1 = self.c3p4c1bn(self.c3p4c1(f_out1))\n",
    "        x_2 = self.c3p4c2bn(self.c3p4c2(f_out1))\n",
    "        x_1 = self.c3p4bc1bn(self.c3p4bc1(x_1))\n",
    "        x_1 = self.c3p4bc2bn(self.c3p4bc2(x_1))\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        pan_out2 = self.c3p4c3bn(self.c3p4c3(x))\n",
    "\n",
    "        p_out1 = self.buc2bn(self.buc2(pan_out2))  # \n",
    "        p_out1 = torch.cat([p_out1, fpn_out1], 1)  # \n",
    "        x_1 = self.c3p4c1bn(self.c3p4c1(p_out1))\n",
    "        x_2 = self.c3p4c2bn(self.c3p4c2(p_out1))\n",
    "        x_1 = self.c3p4bc1bn(self.c3p4bc1(x_1))\n",
    "        x_1 = self.c3p4bc2bn(self.c3p4bc2(x_1))\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        pan_out1 = self.c3p4c3bn(self.c3p4c3(x))\n",
    "\n",
    "        p_out0 = self.buc1bn(self.buc1(pan_out1))  # \n",
    "        p_out0 = torch.cat([p_out0, fpn_out0], 1)  # \n",
    "        x_1 = self.c3p4c1bn(self.c3p4c1(p_out0))\n",
    "        x_2 = self.c3p4c2bn(self.c3p4c2(p_out0))\n",
    "        x_1 = self.c3p4bc1bn(self.c3p4bc1(x_1))\n",
    "        x_1 = self.c3p4bc2bn(self.c3p4bc2(x_1))\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        pan_out0 = self.c3p4c3bn(self.c3p4c3(x))\n",
    "\n",
    "        outputs = [pan_out2, pan_out1, pan_out0]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.fpn'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 4.7296512G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = [torch.rand(1, 256, 32, 40),torch.rand(1, 256, 16, 20),torch.rand(1, 256, 8, 10)]\n",
    "flops, params = profile(fpn(), inputs=[dummy_images])\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fpn(nn.Module):\n",
    "    \"\"\"Focus width and height information into channel space.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.stembn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.cls_conv1 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.cls_conv1bn = nn.BatchNorm2d(256)\n",
    "        self.cls_conv2 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.cls_conv2bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.reg_conv1 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.reg_conv1bn = nn.BatchNorm2d(256)\n",
    "        self.reg_conv2 = nn.Conv2d(\n",
    "            256,\n",
    "            256,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.reg_conv2bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.cls_pred = nn.Conv2d(\n",
    "            256,\n",
    "            3,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.reg_pred = nn.Conv2d(\n",
    "            256,\n",
    "            4,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.obj_pred = nn.Conv2d(\n",
    "            256,\n",
    "            1,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stembn(self.stem(x))\n",
    "        cls_x = x\n",
    "        reg_x = x\n",
    "\n",
    "        cls_feat = self.cls_conv2bn(self.cls_conv2(self.cls_conv1bn(self.cls_conv1(cls_x))))\n",
    "        cls_output = self.cls_pred(cls_feat)\n",
    "\n",
    "        reg_feat = self.reg_conv2bn(self.reg_conv2(self.cls_conv1bn(self.cls_conv1(reg_x))))\n",
    "        reg_output = self.reg_pred(reg_feat)\n",
    "\n",
    "        obj_output = self.obj_pred(reg_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.fpn'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 5.24537856G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = [torch.rand(1, 256, 32, 40),torch.rand(1, 256, 16, 20),torch.rand(1, 256, 8, 10)]\n",
    "flops, params = profile(fpn(), inputs=(dummy_images[0],))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Active_Focus(Focus):\n",
    "    def __init__(self, in_channels, out_channels, ksize=1, stride=1, act=\"gelu\"):\n",
    "        super().__init__(in_channels, out_channels, ksize, stride, act)\n",
    "        #self.conv2 = BaseConv(in_channels * 4, out_channels, ksize, stride, act=act)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * 4, in_channels * 2, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(in_channels * 2, in_channels * 4, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.conv4(self.relu(self.conv3(torch.exp(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Sigmoid'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Temporal_Active_Focus'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.0679936G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 40, 128, 160)\n",
    "flops, params = profile(Temporal_Active_Focus(10, 64, 3), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e3d493db18dfecee561d26c028e75a8172bde10b9fb1f75764229aafdf7eef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
