{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, bias=False, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes, kernel_size=3, bias=False, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # SE\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_down = nn.Conv2d(\n",
    "            planes, planes // 4, kernel_size=1, bias=False)\n",
    "        self.conv_up = nn.Conv2d(\n",
    "            planes // 4, planes, kernel_size=1, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        # Downsample\n",
    "        self.downsample = nn.Conv2d(inplanes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "        self.bn4 = nn.BatchNorm2d(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out1 = self.global_pool(out)\n",
    "        out1 = self.conv_down(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.conv_up(out1)\n",
    "        out1 = self.sig(out1)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.bn4(residual)\n",
    "\n",
    "        res = out1 * out + residual\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNet(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SEResNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Sigmoid'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 1.43986304G\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "dummy_images = torch.rand(1, 64, 60, 80)\n",
    "flops, params = profile(Bottleneck(64, 128, 2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.SEResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 2.4182784G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 10, 480, 640)\n",
    "flops, params = profile(SEResNet(10), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, stride):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel for both cnn and rnn.\n",
    "        cnn_dropout, rnn_dropout: float\n",
    "            cnn_dropout: dropout rate for convolutional input.\n",
    "            rnn_dropout: dropout rate for convolutional state.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        peephole: bool\n",
    "            add connection between cell state to gates\n",
    "        layer_norm: bool\n",
    "            layer normalization \n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = int(self.kernel_size/2)\n",
    "        self.stride = stride\n",
    "        self.bias = True\n",
    "        \n",
    "        self.input_conv = nn.Conv2d(in_channels=self.input_dim, out_channels=4*self.hidden_dim,\n",
    "                                  kernel_size=self.kernel_size,\n",
    "                                  stride = self.stride,\n",
    "                                  padding=self.padding,\n",
    "                                  bias=self.bias)\n",
    "        self.rnn_conv = nn.Conv2d(self.hidden_dim, out_channels=4*self.hidden_dim, \n",
    "                                  kernel_size = self.kernel_size,\n",
    "                                  padding=math.floor(self.kernel_size/2),\n",
    "                                  bias=self.bias)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x_conv = self.input_conv(x)\n",
    "\n",
    "        self.h = Variable(torch.zeros((x_conv.shape[0], self.hidden_dim, x_conv.shape[2], x_conv.shape[3])).to(x.device))\n",
    "        self.c = Variable(torch.zeros((x_conv.shape[0], self.hidden_dim, x_conv.shape[2], x_conv.shape[3])).to(x.device))\n",
    "        \n",
    "        h_cur, c_cur = self.h, self.c\n",
    "\n",
    "        # separate i, f, c o\n",
    "        x_i, x_f, x_c, x_o = torch.split(x_conv, self.hidden_dim, dim=1)\n",
    "        \n",
    "        h_conv = self.rnn_conv(h_cur)\n",
    "        # separate i, f, c o\n",
    "        h_i, h_f, h_c, h_o = torch.split(h_conv, self.hidden_dim, dim=1)\n",
    "        \n",
    "        f = torch.sigmoid((x_f + h_f))  #6 * (H/2 x W/2 x 256)\n",
    "        i = torch.sigmoid((x_i + h_i))  #6 * (H/2 x W/2 x 256)\n",
    "        \n",
    "        g = torch.tanh((x_c + h_c))  #6 * (H/2 x W/2 x 256)\n",
    "        c_next = f * c_cur + i * g\n",
    "\n",
    "        o = torch.sigmoid((x_o + h_o))\n",
    "\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        self.h = h_next\n",
    "        self.c = c_next\n",
    "        self.has_memory = True\n",
    "\n",
    "        return h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.ConvLSTMCell'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 0.7553024G\n"
     ]
    }
   ],
   "source": [
    "dummy_images = torch.rand(1, 256, 15, 20)\n",
    "flops, params = profile(ConvLSTMCell(256,256,3,2), inputs=(dummy_images,))\n",
    "print('FLOPs = ' + str(flops*2/1000**3) + 'G')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e3d493db18dfecee561d26c028e75a8172bde10b9fb1f75764229aafdf7eef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
